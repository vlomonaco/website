---
title:  "Research"
layout: page
---

In this page you will find everything you need to know about my **research interests** and the **work** I'm carrying out in my daily activities as a PhD Student. I'm always looking for collaboration and open for discussion. Fell free to drop me a line at any time! ;-)

<p style="background: rgba(0,0,0,0.06) none repeat scroll 0% 0%; border: 1px solid rgb(222, 222, 222); padding: 1em; border-radius: 5px; text-align: center; margin-top:20px">
&nbsp; <a href="#interests">Research interests</a> &nbsp; | &nbsp; <a href="#projects">Open projects</a> &nbsp;| &nbsp;<a href="#pastprojects">Past projects</a><br>
</p>

<a href="#interests"></a>
<h3 id="interests" style="margin-bottom: 30px;">Research interests</h3>

I have a strong background in Parallel Computing and Data Analytics. My interest has then evolved towards the huge field of Artificial Intelligence, having always been intrigued by the idea of building machines with superhuman abilities. I am now fully engaged in the study of Deep Learning, Continuous/Lifelong learning, and their application in Computer Vision and Internet-Of-Things.

In my PhD I have been focusing on the following questions:

* How much **biological learning systems** can inspire us to build better machines and better learning algorithms? What is the **right level of abstraction**? Can recent advances in Neuroscience provide useful insights to better understand what intelligence really is and design smart algorithms accordingly?

* What does it really mean **Unsupervised Learning**? How much is it important for a learning algorithm? Is it the main feature our brain uses to solve almost any new problem it encounters?

* How much **Incremental** and **Continuous Learning** philosophies should be embraced? Are them useful to help generalization and construct a sophisticate understanding of the external world?

* How currently models can be scaled and shaped towards a single and flexible **universal learning algorithm**? How to automatically discover classes and adjust the architecture to solve a task previously unknown?

<a href="#projects"></a>
<h3 id="projects" style="margin-bottom: 30px;">Open projects</h3>

I'm currently working on the following projects:

* **Evaluating and comparing HTMs and CNNs in continuous/lifelong learning scenarios**.
	I'm currently working to evaluate and compare HTMs and CNNs in continuous/lifelong learning scenarios. This is intriguing for the very nature of the task, which has a biological plausibility. We are primarily focused on tasks in Computer Vision which include temporal coherent data stream.

* **New benchmarks and evaluation techniques for temporal coherent learning algorithms**.
  	Temporal coherence has already shown in the past to be a good surrogate of a supervised signal. However, in literature there are few example of simple and open video benchmark for object recognition. The main goal of this project is to create a new benchmark to train deep learning models using temporal coherence.

* **Smartphones sensors based methods for transportation mode detection**.
	In this more applicative project the main goal is to detect the mobility of the users based only on (low battery consumption) sensors embedded in their mobile phone. The streaming nature of the training data in this task, makes it the natural playground to test our Continuous/Lifelong Machine Learning and Deep Learning algorithms.

<a href="#pastprojects"></a>
<h3 id="pastprojects" style="margin-bottom: 30px;">Past projects</h3>

In the past I've worked on the following projects:

* **Application of AI and Continuous Learning to Software Engineering**.
  	Software Engineering is not one of the first field which pops in mind when thinking at the application of AI algorithms. Yet, many recent works have shown that, for specific tasks such as user-stories disambiguation, bug severity prediction, auto-bug repair, etc.. ML systems can be very useful. In this project the idea was to propose a novel, flexible and extensible  AI framework for Agile-based continuous development projects which can learn and improve after deployment, adapting and refining its prediction capabilities based on previous development cycle.

* **Scaling up the HTM algorithm**.
  	This was a project specifically related to the HTM algorithm. Despite CNNs, the HTM algorithm is still int its infancy. The main effort was focused on scaling up both the algorithm and the implementation to work with images greater than 64x64 pixels and many input channels.

* **Exporting our computer vision experiments to the Nao Robot platform**.
  	Another important project we've worked on (also for teaching purpose) concerns the validation of our algorithms in a robotic context. Since we are mainly interested in biologically inspired deep learning methods, this was the natural validation step of our research.

More information about my past projects as a graduate and PhD student are available at my [Linkedin][linkedin] page!

[linkedin]: https://www.linkedin.com/in/vincenzo
